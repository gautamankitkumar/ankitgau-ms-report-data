{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gautamankitkumar/ankitgau-ms-report-data/blob/main/notebooks/run-mc-simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "We run Monte Carlo simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch relevant packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ase\n",
    "! git clone https://github.com/gautamankitkumar/ankitgau-ms-report-data.git\n",
    "% cd ankitgau-ms-report-data\n",
    "% cd notebooks\n",
    "% cd utils\n",
    "! python3 libsymf_builder.py\n",
    "% cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.db import connect\n",
    "from utils.fcc_helpers import cal_nrg\n",
    "from utils.train_agent import BPNN\n",
    "from utils.fp_calculator import set_sym\n",
    "from ase.build import fcc111\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.fp_calculator import set_sym, db_to_fp\n",
    "from utils.train_agent import Agent, get_scaling\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "m = 1\n",
    "n = 4000\n",
    "np.random.seed(seed=42)\n",
    "\n",
    "full_data = connect('./datasets/CuAgAu.db')\n",
    "\n",
    "if os.path.exists('./datasets/test.db'):\n",
    "    os.remove('./datasets/test.db')\n",
    "if os.path.exists('./datasets/train.db'):\n",
    "    os.remove('./datasets/train.db')\n",
    "if os.path.exists('./datasets/valid.db'):\n",
    "    os.remove('./datasets/valid.db')\n",
    "\n",
    "train_data = connect('./datasets/train.db')\n",
    "valid_data = connect('./datasets/valid.db')\n",
    "test_data = connect('./datasets/test.db')\n",
    "\n",
    "#  Generate different train and test dataset\n",
    "valid_and_test_ids = np.random.choice(np.arange(1,n),n//5,replace=False)\n",
    "valid_ids = valid_and_test_ids[:n//10]\n",
    "test_ids = valid_and_test_ids[n//10:]\n",
    "# Write the corresponding atoms object into each databases\n",
    "for i in range(1,n+1):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    row = full_data.get_atoms(selection = i)\n",
    "    if i in test_ids:\n",
    "        test_data.write(row)\n",
    "    elif i in valid_ids:\n",
    "        valid_data.write(row)\n",
    "    else:\n",
    "        train_data.write(row)\n",
    "Name = 'CuAgAu'\n",
    "elements = ['Cu', 'Ag', 'Au']\n",
    "Gs = [2]\n",
    "cutoff = 6.0\n",
    "g2_etas = [0.05, 4.0, 20.0, 80.0]\n",
    "g2_Rses = [0.0]\n",
    "\n",
    "params_set = set_sym(elements, Gs, cutoff, g2_etas=g2_etas, g2_Rses=g2_Rses)\n",
    "\n",
    "\n",
    "# calculate fingerprints for databases\n",
    "train_db = connect('./datasets/train.db')\n",
    "train_data = db_to_fp(train_db, params_set)\n",
    "torch.save(train_data, f'./{Name}/CuAgAu-train-dft.sav')\n",
    "\n",
    "valid_db = connect('./datasets/valid.db')\n",
    "valid_data = db_to_fp(valid_db, params_set)\n",
    "torch.save(valid_data, f'./{Name}/CuAgAu-valid-dft.sav')\n",
    "\n",
    "test_db = connect('./datasets/test.db')\n",
    "test_data = db_to_fp(test_db, params_set)\n",
    "torch.save(test_data, f'./{Name}/CuAgAu-test-dft.sav')\n",
    "\n",
    "# load data\n",
    "train_data = torch.load(f'./{Name}/CuAgAu-train-dft.sav')\n",
    "valid_data = torch.load(f'./{Name}/CuAgAu-valid-dft.sav')\n",
    "test_data = torch.load(f'./{Name}/CuAgAu-test-dft.sav')\n",
    "scale_file = f'./{Name}/scale.sav'\n",
    "\n",
    "if not os.path.isfile(scale_file):\n",
    "    scale = get_scaling(train_data)\n",
    "    torch.save(scale, scale_file)\n",
    "else:\n",
    "    scale = torch.load(scale_file)\n",
    "\n",
    "# scale training fp\n",
    "train_data['b_fp'] = (train_data['b_fp'] - scale['fp_min']) / (scale['fp_max'] - scale['fp_min'])\n",
    "valid_data['b_fp'] = (valid_data['b_fp'] - scale['fp_min']) / (scale['fp_max'] - scale['fp_min'])\n",
    "test_data['b_fp'] = (test_data['b_fp'] - scale['fp_min']) / (scale['fp_max'] - scale['fp_min'])\n",
    "\n",
    "device = torch.device('cpu')\n",
    "# for key in train_data.keys():\n",
    "# \ttrain_data[key] = train_data[key].to(device)\n",
    "# \tvalid_data[key] = valid_data[key].to(device)\n",
    "\n",
    "layer_nodes = [10,10]\n",
    "activations = ['tanh','tanh']\n",
    "lr = 0.1\n",
    "\n",
    "# create model and train\n",
    "element = torch.tensor([29, 47, 79])  # should have the same order with the elements above\n",
    "model_paths = [f'./{Name}/model_for_{i}.sav' for i in element.tolist()]\n",
    "log_name = f'./{Name}/train_log.txt'\n",
    "\n",
    "agent = Agent(train_data=train_data, valid_data=valid_data, model_paths=model_paths, test_data=test_data,\n",
    "              layer_nodes=layer_nodes, activation=activations, lr=lr, max_iter=20, history_size=100, device=device)\n",
    "\n",
    "agent.train(log_name=log_name, n_epoch=50, interupt=True, val_interval=1,\n",
    "            is_force=False, nrg_convg=2, force_convg=20, nrg_coef=1, force_coef=1)\n",
    "# Energy convergence in meV, Force convergence in meV/Angstrom\n",
    "# No Force fitting from the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
